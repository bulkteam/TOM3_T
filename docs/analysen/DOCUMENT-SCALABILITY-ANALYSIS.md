# TOM3 - Dokumenten-Service Skalierbarkeits-Analyse

## Frage: Ist der Ansatz bei 10-20k Dokumenten noch valide?

**Kurze Antwort: ‚úÖ Ja, aber mit einigen Optimierungen.**

## 1. MariaDB FULLTEXT Suche

### Aktueller Stand
- FULLTEXT Index auf `extracted_text` (LONGTEXT)
- FULLTEXT Index auf `title` (VARCHAR(255))

### Performance bei 10-20k Dokumenten

**‚úÖ Gut skalierbar:**
- MariaDB FULLTEXT kann problemlos 10-20k Dokumente handhaben
- Query-Zeit: < 100ms bei typischen Suchen
- Index-Gr√∂√üe: ~10-20% der Text-Gr√∂√üe (akzeptabel)

**‚ö†Ô∏è Potenzielle Probleme:**
- Sehr lange `extracted_text` (> 1MB pro Dokument) ‚Üí Index wird gro√ü
- Viele gleichzeitige FULLTEXT Queries ‚Üí CPU-Last

**Empfehlung:**
- ‚úÖ F√ºr 10-20k Dokumente: **Aktueller Ansatz ist ausreichend**
- ‚ö†Ô∏è Ab ~50k Dokumenten: Performance-Monitoring
- üîÑ Ab ~100k Dokumenten: OpenSearch in Betracht ziehen

### Optimierungen (sofort umsetzbar)

```sql
-- Limit f√ºr extracted_text (verhindert riesige Indizes)
ALTER TABLE documents 
    MODIFY COLUMN extracted_text LONGTEXT 
    COMMENT 'Max. 1MB f√ºr FULLTEXT Performance';

-- Oder: Separate Tabelle f√ºr sehr lange Texte
CREATE TABLE document_text_long (
    document_uuid CHAR(36) PRIMARY KEY,
    extracted_text LONGTEXT,
    FULLTEXT idx_extracted_text (extracted_text)
) ENGINE=InnoDB;
```

## 2. Storage (Lokales Filesystem)

### Aktueller Stand
- Hash-basierte Struktur: `storage/{tenant}/{aa}/{bb}/{sha256}`
- Deduplication √ºber Unique Index

### Performance bei 10-20k Dokumenten

**‚úÖ Sehr gut skalierbar:**
- 10-20k Dateien sind kein Problem
- Hash-Struktur verteilt Dateien auf ~256 Unterverzeichnisse (aa/bb)
- Durchschnittlich ~40-80 Dateien pro Verzeichnis (sehr gut)

**Berechnung:**
```
20.000 Dokumente / 256 Verzeichnisse = ~78 Dateien/Verzeichnis
‚Üí Sehr gut handhabbar f√ºr Filesystem
```

**‚ö†Ô∏è Potenzielle Probleme:**
- Sehr gro√üe Dateien (> 100MB) ‚Üí Backup-Zeit
- Viele gleichzeitige Downloads ‚Üí I/O-Last

**Empfehlung:**
- ‚úÖ F√ºr 10-20k Dokumente: **Aktueller Ansatz ist optimal**
- ‚ö†Ô∏è Ab ~100k Dokumenten: Monitoring, aber noch OK
- üîÑ Ab ~500k Dokumenten: S3/MinIO in Betracht ziehen

### Optimierungen (optional)

```php
// Storage-Pfad mit mehr Ebenen (f√ºr sehr gro√üe Mengen)
// Aktuell: {tenant}/{aa}/{bb}/{sha256}
// Sp√§ter: {tenant}/{aa}/{bb}/{cc}/{dd}/{sha256}
// ‚Üí 65.536 Verzeichnisse statt 256
```

## 3. Deduplication (Unique Index)

### Aktueller Stand
- Unique Index auf `(tenant_id, sha256, size_bytes)`
- O(1) Lookup √ºber Index

### Performance bei 10-20k Dokumenten

**‚úÖ Perfekt skalierbar:**
- Index-Lookup ist O(1) - unabh√§ngig von Dokumenten-Anzahl
- Selbst bei 1 Million Dokumenten: < 1ms Lookup
- Keine Performance-Probleme erwartet

**Empfehlung:**
- ‚úÖ **Keine √Ñnderungen n√∂tig** - skaliert perfekt

## 4. Datenbank-Queries

### Aktueller Stand
- JOINs zwischen `documents`, `blobs`, `document_attachments`
- Indizes auf Foreign Keys
- Indizes auf h√§ufig gefilterten Feldern

### Performance bei 10-20k Dokumenten

**‚úÖ Gut skalierbar:**
- JOINs mit Indizes: < 50ms bei typischen Queries
- `getEntityDocuments()`: Sehr schnell (Index auf `entity_type`, `entity_uuid`)

**‚ö†Ô∏è Potenzielle Probleme:**
- Queries ohne Index-Nutzung (z.B. `LIKE '%text%'` statt FULLTEXT)
- N+1 Query Problem (wenn nicht optimiert)

**Empfehlung:**
- ‚úÖ F√ºr 10-20k Dokumente: **Aktueller Ansatz ist ausreichend**
- ‚ö†Ô∏è Monitoring: Query-Logs pr√ºfen
- üîÑ Optimierungen: Prepared Statements, Query-Caching

### Optimierungen (sofort umsetzbar)

```php
// Query-Caching f√ºr h√§ufige Abfragen
// z.B. Entity-Dokumente (√§ndern sich selten)
$cacheKey = "entity_docs_{$entityType}_{$entityUuid}";
if ($cached = $cache->get($cacheKey)) {
    return $cached;
}
// ... Query ausf√ºhren ...
$cache->set($cacheKey, $results, 300); // 5 Min TTL
```

## 5. Speicher-Bedarf

### Sch√§tzung f√ºr 10-20k Dokumente

**Annahmen:**
- Durchschnittliche Dateigr√∂√üe: 2MB
- Durchschnittliche `extracted_text` L√§nge: 50KB
- Durchschnittliche Metadaten: 1KB

**Berechnung:**
```
20.000 Dokumente:
- Storage: 20.000 √ó 2MB = 40GB
- DB (extracted_text): 20.000 √ó 50KB = 1GB
- DB (Metadaten): 20.000 √ó 1KB = 20MB
- Indizes: ~200MB
- Gesamt: ~41GB
```

**Empfehlung:**
- ‚úÖ **Machbar** - Standard-Server kann das handhaben
- ‚ö†Ô∏è Backup-Strategie wichtig (40GB+)
- üîÑ Kompression f√ºr √§ltere Dokumente (optional)

## 6. Konkrete Performance-Tests

### Empfohlene Metriken

1. **FULLTEXT Suche:**
   - Ziel: < 200ms bei 20k Dokumenten
   - Test: 100 gleichzeitige Suchen

2. **Entity-Dokumente abrufen:**
   - Ziel: < 50ms
   - Test: Org mit 100 Dokumenten

3. **Upload + Dedup:**
   - Ziel: < 2s f√ºr 10MB Datei
   - Test: Parallele Uploads

4. **Download:**
   - Ziel: < 100ms Overhead (ohne Datei-Transfer)
   - Test: 50 gleichzeitige Downloads

## 7. Grenzen und Migration-Pfad

### Wann wird es kritisch?

| Metrik | 10-20k | 50k | 100k | 500k+ |
|--------|--------|-----|------|-------|
| FULLTEXT Suche | ‚úÖ < 200ms | ‚ö†Ô∏è 500ms | ‚ö†Ô∏è 1-2s | ‚ùå > 5s |
| Storage I/O | ‚úÖ OK | ‚úÖ OK | ‚ö†Ô∏è Langsam | ‚ùå Problem |
| DB-Queries | ‚úÖ < 50ms | ‚úÖ < 100ms | ‚ö†Ô∏è 200ms | ‚ùå > 500ms |
| Dedup-Lookup | ‚úÖ < 1ms | ‚úÖ < 1ms | ‚úÖ < 1ms | ‚úÖ < 1ms |

### Migration-Pfad (wenn n√∂tig)

**Phase 1 (10-20k):** ‚úÖ Aktueller Ansatz
- MariaDB FULLTEXT
- Lokales Filesystem
- Keine √Ñnderungen n√∂tig

**Phase 2 (50-100k):** ‚ö†Ô∏è Optimierungen
- Query-Caching
- Index-Optimierungen
- Monitoring

**Phase 3 (100k+):** üîÑ Migration
- OpenSearch f√ºr Suche
- S3/MinIO f√ºr Storage (optional)
- CDN f√ºr Downloads (optional)

## 8. Empfehlungen f√ºr 10-20k Dokumente

### ‚úÖ Sofort umsetzbar (Performance)

1. **Query-Caching** (optional, aber empfohlen)
   ```php
   // F√ºr getEntityDocuments() - √§ndert sich selten
   $cache->get("entity_docs_{$type}_{$uuid}");
   ```

2. **Index-Monitoring**
   ```sql
   -- Pr√ºfe Index-Nutzung
   EXPLAIN SELECT ... FROM documents ...;
   ```

3. **Backup-Strategie**
   - Storage + DB separat backuppen
   - Incremental Backups f√ºr Storage

### ‚ö†Ô∏è Monitoring (wichtig)

1. **Query-Logs aktivieren**
   ```sql
   SET GLOBAL slow_query_log = 'ON';
   SET GLOBAL long_query_time = 1; -- 1 Sekunde
   ```

2. **Storage-Monitoring**
   - Festplatten-Space
   - I/O-Wartezeiten

3. **FULLTEXT Performance**
   - Query-Zeiten tracken
   - Index-Gr√∂√üe √ºberwachen

### üîÑ Sp√§ter (wenn n√∂tig)

1. **OpenSearch** (ab ~100k Dokumenten)
2. **S3/MinIO** (ab ~500k Dokumenten oder bei Cloud-Deployment)
3. **CDN** (bei vielen Downloads)

## 9. Fazit

### ‚úÖ F√ºr 10-20k Dokumente: **Aktueller Ansatz ist valide**

**Begr√ºndung:**
- MariaDB FULLTEXT skaliert gut bis ~50k
- Hash-basierte Storage-Struktur ist optimal
- Deduplication ist O(1) - keine Probleme
- DB-Queries sind mit Indizes schnell

**Was zu beachten ist:**
- Monitoring einrichten
- Query-Caching optional hinzuf√ºgen
- Backup-Strategie planen

**Migration-Pfad:**
- Ab ~50k: Optimierungen
- Ab ~100k: OpenSearch in Betracht ziehen
- Ab ~500k: S3/MinIO optional

---

*Analyse erstellt: 2026-01-01*


